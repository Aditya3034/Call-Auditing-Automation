# ğŸ§ Call Auditing Automation â€” Whisper + Gemini Integration

This FastAPI application enables automated call auditing by transcribing audio recordings, structuring transcripts, generating call summaries, and evaluating agent interactions using OpenAI's Whisper and Google Gemini LLMs.

---

## ğŸš€ Setup Instructions

### 1. Clone the repository

```bash
git clone https://github.com/your-username/Call-Auditing-Automation.git
cd Call-Auditing-Automation
```

### 2. Create and activate a virtual environment

```bash
python -m venv .venv
source .venv/bin/activate  # On Windows: .venv\Scripts\activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Run the application

```bash
uvicorn main:app --reload
```

---

## ğŸ“ API Endpoints

Interactive docs: [http://localhost:8000/docs](http://localhost:8000/docs)

| Method | Endpoint                            | Description                                             |
|--------|-------------------------------------|---------------------------------------------------------|
| POST   | `/`                                 | Health check â€” returns `"Application is started"`       |
| POST   | `/api/analyze-audio`               | Full workflow: transcribe, structure, summarize, score  |
| POST   | `/api/structure-transcript`        | Format raw transcript into structured format            |
| POST   | `/api/generate-summary`            | Create a title and summary from transcript              |
| POST   | `/api/evaluate-metrics`            | Score structured transcript using interaction metrics   |
| GET    | `/health`                          | Returns model status, Gemini initialization, timestamp  |

---

## ğŸ§ª Sample Requests

### `/api/structure-transcript`

```json
{
  "transcript": "Customer: I'm trying to cancel my ticket because of an emergency..."
}
```

### `/api/generate-summary`

```json
{
  "transcript": "Structured transcript goes here..."
}
```

### `/api/evaluate-metrics`

```json
{
  "transcript": "Structured transcript goes here..."
}
```

---

## ğŸ›  Technologies Used

- ğŸ™ï¸ Whisper Large V3 â€” audio transcription
- ğŸ§  Gemini 1.5 Flash â€” transcript analysis, summarization, scoring
- ğŸš€ FastAPI â€” backend framework for endpoints
- ğŸ” Modular LLM dispatcher â€” supports Gemini, OpenAI, Ollama, Sarvam, DeepSeek
- ğŸ“¦ Uvicorn, Pydantic â€” server runtime and schema validation

---

## âœ… Health Check Output

```http
GET /health
```

Returns:

```json
{
  "status": "healthy",
  "whisper_loaded": true,
  "gemini_initialized": true,
  "timestamp": "2025-07-12T06:10:32.821Z"
}
```

---

## ğŸ“‚ Response Example (`/api/analyze-audio`)

```json
{
  "structured_transcript": "[00:00:00] Agent (calm): Hello, thank you for calling...",
  "title": "Flight Cancellation Due to Emergency",
  "summary": "Customer contacted support regarding...",
  "evaluation_metrics": {
    "Empathy": { "score": 9, "comment": "Agent demonstrated sincere concern..." },
    ...
  },
  "success": true
}
```

---

## ğŸ” Notes

- Set your Gemini API key securely via environment variables or config file
- Whisper model must be loaded before handling requests
- Audio is processed securely via temporary file handling
- Transcript is saved locally with timestamped filename

---

## ğŸ“¬ Contributions

Pull requests and feature suggestions welcome!  
Help improve evaluation logic, add more LLMs, or enhance output display.

---
